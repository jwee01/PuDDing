<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>üçÆ PuDDing: Prompt-routed Dynamic Depth Pruning</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">üçÆ PuDDing: Prompt-routed Dynamic Depth Pruning</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://openreview.net/profile?id=~Juyun_Wee1" target="_blank">Juyun Wee</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://openreview.net/profile?id=~Minjae_Park1" target="_blank">Minjae_Park</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="https://jaeho-lee.github.io" target="_blank">Jaeho Lee</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Pohang University of Science and Technology (POSTECH), South Korea.<br>ICML 2025</span>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2502.04348" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a> -->
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/tada0347/PuDDing" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2502.04348" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
        <!-- Your video here -->
        <!-- <source src="static/videos/banner_video.mp4" -->
        <!-- type="video/mp4"> -->
      <!-- </video> -->
      <img src="static/images/figure1.png"
      class="interpolation-image"
      alt="Framework image"
      style="width: 50%; display: block; margin: 0 auto; margin-bottom: 2rem;" />
      <h2 class="subtitle has-text-centered">
        Our method, PuDDing (Prompt-routed Dynamic Depth Pruning), reduces memory usage and accelerates inference of large language models by selectively removing Transformer blocks based on the input prompt using a lightweight pretrained router.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">üëÄ Quick glance at gains</h2>
        <div class="content has-text-justified" style="overflow-x: auto;">
          <table style="min-width: 600px; width: 100%; border-collapse: collapse;">
            <thead style="background-color: #f0f0f0;">
              <tr>
                <th style="padding: 12px; border: 1px solid #ccc;"></th>
                <th style="padding: 12px; border: 1px solid #ccc;">Dense LLaMA‚Äë3.1‚Äë8B</th>
                <th style="padding: 12px; border: 1px solid #ccc;">PuDDing (20‚ÄØ% pruned)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td style="padding: 12px; border: 1px solid #ccc;"><strong>Memory</strong></td>
                <td style="padding: 12px; border: 1px solid #ccc;">16‚ÄØGB</td>
                <td style="padding: 12px; border: 1px solid #ccc;">12.8‚ÄØGB (‚Üì‚ÄØ3.2‚ÄØGB)</td>
              </tr>
              <tr>
                <td style="padding: 12px; border: 1px solid #ccc;"><strong>Pre‚Äëfill time</strong></td>
                <td style="padding: 12px; border: 1px solid #ccc;">251‚ÄØms</td>
                <td style="padding: 12px; border: 1px solid #ccc;">206‚ÄØms (1.22√ó faster)</td>
              </tr>
              <tr>
                <td style="padding: 12px; border: 1px solid #ccc;"><strong>Accuracy</strong></td>
                <td style="padding: 12px; border: 1px solid #ccc;">74.9‚ÄØ%</td>
                <td style="padding: 12px; border: 1px solid #ccc;">62.93‚ÄØ% (‚Äë11.97‚ÄØ%p)</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- End paper abstract -->


<!-- Observation -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">üîç Under the hood (30‚ÄØs read)</h2>
        <div class="content has-text-justified">
          <ul>
            <li><strong>Task‚Äëaware pruning</strong>: Block importance changes with the question. Our router learns this mapping from a handful of calibration datasets.</li>
            <li><strong>Single‚Äëshot routing</strong>: Decisions are made once per prompt, so runtime overhead stays below <strong>8‚ÄØms</strong>.</li>
            <li><strong>Plug‚Äëand‚Äëplay</strong>: Works on LLaMA, Vicuna, OPT and friends ‚Äî no retraining of the backbone required.</li>
          </ul>

        </div>
      </div>
    </div>
  </div>
</section>





















<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">

              <p>
                Depth pruning aims to reduce the inference cost of a large language model without any hardware-specific complications, by simply removing several less important transformer blocks. However, our empirical findings suggest that the importance of a transformer block may be highly task-dependent -- a block that is crucial for a task can be removed without degrading the accuracy on another task. Based on this observation, we develop a dynamic depth pruning algorithm, coined PuDDing (Prompt-routed Dynamic Depth Pruning), which determines which blocks to omit from the model based on the input prompt. PuDDing operates by training a lightweight router to predict the best omission set among a set of options, where this option set has also been constructed in a data-driven manner. Empirical results on commonsense reasoning benchmarks demonstrate that PuDDing effectively accelerates the inference language models, and achieves better on-task performance than static depth pruning baselines.
              </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Observation -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Observation</h2>
        <div class="content has-text-justified">
          <img src="static/images/observaion1.png"
               class="interpolation-image"
               alt="Framework image"
               style="width: 50%; display: block; margin: 0 auto;" />
               <p>
                A key motivation behind <strong>PuDDing</strong> is the observation that the importance of transformer blocks in large language models is highly task-dependent. A block that is essential for one task may be redundant for another. For example, in our experiments with LLaMA 3.1-8B, replacing block 30 with block 29 led to a sharp accuracy drop on BoolQ (over 20%p), while slightly improving performance on PIQA and WinoGrande. This suggests that different blocks capture task-specific knowledge.
              </p>
              <p>
                These findings highlight the limitation of static pruning and motivate our core idea: pruning should be <em>dynamic</em> and <em>prompt-aware</em>. Rather than relying on a fixed omission set, <strong>PuDDing</strong> adapts the model architecture to each input prompt, achieving both efficiency and task-specialized performance.
              </p>
              
        </div>
      </div>
    </div>
  </div>
</section>




<!-- Framework -->
<section class="section hero is is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Framework</h2>
        <div class="content has-text-justified">
          <img src="static/images/4_model_pipeline2.jpg"
               class="interpolation-image"
               alt="Framework image"
               style="max-width: 100%;" />
               <p></p>
              <p>
                
                The framework works in two stages. First, we construct a small but effective pool of candidate omission sets by evaluating task-specific losses on calibration datasets. Second, we train a transformer-based router that maps each prompt to the most suitable omission set in this pool.
              </p>
              <p>
                At inference time, given a prompt, the router selects an omission set that best preserves task performance. The model then loads only the retained blocks into high-speed memory, skipping the pruned ones. This design significantly reduces loading time and computation cost while maintaining high accuracy across a variety of tasks.
              </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Main result -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Main Results</h2>
        <div class="content has-text-justified">
		<img src="static/images/main_result.jpg"
		class="interpolation-image"
		alt="Interpolate start reference image."
		style="max-width: 100%;"/>
    <p>
      We evaluated <strong>PuDDing</strong> on zero-shot commonsense reasoning tasks using the LLaMA-3.1 8B model and compared its performance with state-of-the-art compression methods. As shown in the results above, PuDDing consistently achieves the highest average accuracy across all tested sparsity levels. In particular, when pruning 7 blocks (over 20% sparsity), it outperforms the best baseline by nearly <strong>3 percentage points</strong>.
    </p>
    <p>
      In addition, PuDDing demonstrates strong generalization on more complex, unseen tasks such as OpenBookQA, MathQA, and MMLU. Even though these tasks were not seen during router training, PuDDing maintains superior performance compared to existing pruning baselines. For detailed results, please refer to <em>Table 5 in our paper</em>.
    </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Closer look -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Pruning Behavior and Latency Overview</h2>
        <div class="content has-text-justified">
  	<!-- <p>
	To answer why the proposed student-guided masking works well, we conduct an in-depth comparative analysis. Our observations can be summarized as follows:
		<ul>
		  <li>Student-guided masking provides a good curriculum for distillation, enhancing the student training.</li>
		  <li>Masking the tokens at input preserved the supervision quality better than gradually removing tokens in the intermediate layers</li>
		  <li>In supervised knowledge distillation, masking the teacher model is beneficial, as masking the student significantly degrades accuracy, contrary to standard mask-based SSL practices.</li>
		</ul>
	</p> -->
	<img src="static/images/heatmap_llama.png"
	class="interpolation-image"
	alt="Interpolate start reference image."
	style="max-width: 100%;"/>
	<p>
    We analyze the pruning patterns of LLaMA-3.1 8B under 20% sparsity across zero-shot tasks. Some blocks (e.g., 20, 26, 27) are consistently pruned, while others (e.g., 1‚Äì3, 5‚Äì8) are almost always retained. Certain blocks show task-specific behavior‚Äîfor instance, block 4 is often pruned in ARC tasks but retained in PIQA and WinoGrande. Similar trends are observed in OPT and Vicuna models (see Appendix C).
	</p>
	<img src="./static/images/inference_speed.png"
	class="interpolation-image"
	alt="Interpolate start reference image."
	style="max-width: 100%;"/>
	<p> 
		Above table shows that PuDDing, with 21.88% sparsity, achieves a consistent 1.2√ó speedup over the dense LLaMA-3.1 8B model on both A100 and RTX 6000 Ada GPUs‚Äîacross both pre-fill and generation stages‚Äîwhile the routing overhead remains minimal (4‚Äì8ms).
	</p>
        </div>
      </div>
    </div>
  </div>
</section>
	
<!-- Acknowledgements
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Acknowledgements</h2>
        <div class="content has-text-justified">
          <p>
            This work was partly supported by the National Research Foundation of Korea (NRF) grant funded by the Korean government (MSIT) (RS2023-00213710, RS2023-00210466), and the Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korean government (MSIT) (RS-2019-II191906, Artificial Intelligence Graduate School Program (POSTECH), RS-2022-II220959, Few-Shot learning of Causal Inference in Vision and Language
for Decision Making), and POSCO Creative Ideas grant (2023Q024, 2023Q032).
          </p>
        </div>
      </div>
    </div>
  </div>
</section> -->
  
<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{wee2025prompt,
          title={Prompt-based Depth Pruning of Large Language Models},
          author={Wee, Juyun and Park, Minjae and Lee, Jaeho},
          booktitle={International Conference on Machine Learning},
          year={2025}
        }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
